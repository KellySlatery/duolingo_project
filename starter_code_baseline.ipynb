{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: English to Spanish Morphosyntax Order of Acqusition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelly Slatery | US-DSI-10 | 03.13.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Using data from the [2018 Duolingo Shared Task Challenge on Second Language Acquisition Modeling (SLAM)](#https://sharedtask.duolingo.com/2018.html), extract a common order of acquisition for morphosyntactical features of Spanish amongst users using the English platform to learn Spanish. Morphosyntacic features are parts of word that actually give grammatical information, such as the plural -s or different types of conjugations in Spanish.\n",
    "\n",
    "We will look at data from English speakers learnign Spanish for three major reasons:\n",
    "- The U.S. has one of the highest populations of monolinguals in the world.\n",
    "- Foreign language education in the U.S. is subpar and needs reform based on research.\n",
    "- Spanish is increasingly important in the U.S. as the U.S. Spanish-speaking population grows and generations continue to learn and use Spanish.\n",
    "\n",
    "The applications and utility of discovering and supporting a data-informed order of acquisiton for morphosyntactic festures of Spanish are two-fold. First, understanding the natural order in which students acquire different features of Spanish can help those who write Spanish textbooks and Spanish teachers alike structure their lessons in a way more conducive to learning. Second, understanding this natural order can positively impact motivation in Spanish-learning by adjusting both teachers' and students' expectations for student learning to hopefully increase effectiveness of error correction and student self-esteem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Methods and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data needs to be compiled into a DataFrame for easier analysis and filtered to only those sessions where the format is 'reverse_translate' and the session is either 'lesson' or 'practice'. This will most likely require AWS, SQL, or perhaps just cutting down on the data used. Next, as the basis for the classification models, we will label a certain subset of the train data prompt tokens for which possible errors can be made (Ex. {1: plural, 2: ser vs estar, 3: regular past tense, 4: irregular past tense, ...}). Using these generated labels, we can build a model to generate labels for the remaining millions of tokens.\n",
    "\n",
    "This project will consist of three models:\n",
    "\n",
    "- Using a classification model, most likely an ensemble decision tree (random forest, bagged classfier, extra trees), create a label for what error a user made in each prompt. This will mainly be based on the column labeling error/no error [0,1] and the accompanying word (tokens) and its details (Ex. {1: plural, 2: ser vs estar, 3: regular past tense, 4: irregular past tense, ...}). Then, to identify which errors are most common across the board on each prompt, we will sort the data by prompt and find the value counts for the labeled error column.\n",
    "\n",
    "- Using another classification model, most likely an ensemble decision tree (random forest, bagged classfier, extra trees), create a label for what errors are possible, given a prompt. This will be based mainly on what words (tokens) are present in the prompt and their token details.\n",
    "\n",
    "- Using a neural network, predict based on the features available, like days and time, along with a new calculation of whether or not the user made the morphosyntactic error labeled (combining above possible error label, with typo of error label, and provided [0,1] label, where 1 indicates that the student made an error), predict, given the next prompt, whether or not the student will make the possible morphosyntactic mistake.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective and Success Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Produce a table describing the order of acquisition of Spanish morphosyntactic features for English-speaking learners, and describe which token features are most represented in errors. \n",
    "\n",
    "Success Metrics: \n",
    "\n",
    "For the [2018 Duolingo Shared Task Challenge on Second Language Acquisition Modeling (SLAM)](#https://sharedtask.duolingo.com/2018.html), the success metrics used were AUC and F1 scores. This also makes sense for our third prediction model, as well as our two classification models. For the classificaiton models, we will be labeling data manually and then using a model to label further data. For the third model, given that there is a development and test dataset, we will be testing our model predictions of errors on labeled data (supervised learning) and evaluating success based on accuracy of these predictions, which works with AUC and F1. \n",
    "\n",
    "The predictions will be based on two models above that label morphosyntactic features based on supervised leanring from manually labeling data, and then our error predictions use these classifications to determine whether a student will make an error or not on given words in a given prompt at a given time in their study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risks and Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risks / Perceived Challenges:\n",
    "- The dataset is quite robust with over 2 million tokens from over 6,000 users worldwide. It is impossible to analyze all of this data the way we've been doing in class, so it will be necessary to either cut down the data or upload it to AWS and figure out how AWS connects to jupyter notebooks.\n",
    "- The data is not yet in a DataFrame and I am only comfortable as of yet performing data analysis on pandas DataFrames. Because the data seems to be compatible with a database-style organization, SQL might be helpful. I like using SQL, but I have no idea how to integrate it into what I'm doing or build a database from the data.\n",
    "- I may only be able to finish the first model of classifying error types by graduation day. Though I could finish it later, the first model is only a stepping stone, and may not be as interesting or as helpful to my audience (classmates, employers, etc.).\n",
    "\n",
    "Assumptions:\n",
    "- This data does not provide the student response. Rather, it provides an indication of on which tokens in the user-provided translation the user made an error. Thus, we have to assume that the user's mistake was, in fact, morphosyntactic if the error was made on a word that should contain one of the morphosyntactic qualities we are looking for (and labeled [0,1,...,n]). \n",
    "- In labeling morphosyntactic error types, I will have to assume different groups of error types with being aware of their representation in the dataset. I will base these error labels on previous research on the order of acquisition for Spanish morphosyntactice features, but perhaps it is this grouping that needs to be reanalyzed in future studies of order of acquisition.\n",
    "- Lessons are often based on only one morphosyntactic feature at a time, so this will need to be taken into account in our models. It may make sense to compare only practice sessions errors, rather than lesson errors. On the other hand, previously learned morphosyntactice features are most likely included in future lesson prompts as well, so it may not make a huge difference, except that we need to compare errors by feature over time rather than errors at a time amongst features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below data summary is from sections \"Prediction Task\" and \"Data Format\" from [2018 Duolingo Shared Task Challenge on Second Language Acquisition Modeling (SLAM)](#https://sharedtask.duolingo.com/2018.html):\n",
    "\n",
    "\"In these exercises, students construct answers in the L2 they are learning, and make various mistakes along the way. The goal of this task is to predict future mistakes that learners of English, Spanish, and French will make based on a history of the mistakes they have made in the past. More specifically, the data set contains more than 2 million tokens (words) from answers submitted by more than 6,000 Duolingo students over the course of their first 30 days.\n",
    "\n",
    "We provide token-level labels and dependency parses for the most similar correct answer to each student submission. \n",
    "\n",
    "...\n",
    "\n",
    "Most tokens (about 83%) are perfect matches and are given the label 0 for \"OK.\" Tokens that are missing or spelled incorrectly (ignoring capitalization, punctuation, and accents) are given the label 1 denoting a mistake.\n",
    "\n",
    "Note: For this task, we provide labels but not actual student responses.\n",
    "\n",
    "...\n",
    "\n",
    "The data format is inspired by the Universal Dependencies CoNNL-U format. Each student exercise is represented by a group of lines separated by a blank line: one token per line prepended with exercise-level metadata.\n",
    "\n",
    "...\n",
    "\n",
    "The first line of each exercise group (beginning with #) contains the following metadata about the student, session, and exercise:\n",
    "\n",
    "user: a B64 encoded, 8-digit, anonymized, unique identifier for each student (may include / or + characters)\n",
    "countries: a pipe (|) delimited list of 2-character country codes from which this user has done exercises\n",
    "days: the number of days since the student started learning this language on Duolingo\n",
    "client: the student's device platform (one of: android, ios, or web)\n",
    "session: the session type (one of: lesson, practice, or test; explanation below)\n",
    "format: the exercise format (one of: reverse_translate, reverse_tap, or listen; see figures above)\n",
    "time: the amount of time (in seconds) it took for the student to construct and submit their whole answer (note: for some exercises, this can be null due to data logging issues)\n",
    "These fields are separated by whitespaces on the same line, and key:value pairs are denoted with a colon (:).\n",
    "\n",
    "The lesson sessions (about 77% of the data set) are where new words or concepts are introduced, although lessons also include a lot previously-learned material (e.g., each exercise tries to introduce only one new word or tense, so all other tokens should have been seen by the student before). The practice sessions (22%) should contain only previously-seen words and concepts. The test sessions (1%) are quizzes that allow a student \"skip\" a particular skill unit of the curriculum (i.e., the student may have never seen this content before in the Duolingo app, but may well have had prior knowledge before starting the course).\n",
    "\n",
    "The remaining lines in each exercise group represent each token (word) in the correct answer that is most similar to the student's answer, one token per line, arranged into seven (7) columns separated by whitespaces:\n",
    "\n",
    "- A Unique 12-digit ID for each token instance: the first 8 digits are a B64-encoded ID representing the session, the next 2 digits denote the index of this exercise within the session, and the last 2 digits denote the index of the token (word) in this exercise\n",
    "- The token (word)\n",
    "- Part of speech in Universal Dependencies (UD) format\n",
    "- Morphological features in UD format\n",
    "- Dependency edge label in UD format\n",
    "- Dependency edge head in UD format (this corresponds to the last 1-2 digits of the ID in the first column)\n",
    "- The label to be predicted (0 or 1)\n",
    "- All dependency features (columns 3-6) are generated by the Google SyntaxNet dependency parser using the language-agnostic Universal Dependencies tagset. (In other words, these morpho-syntactic features should be comparable across all three tracks in the shared task. Note that SyntaxNet isn't perfect, so parse errors may occur.)\n",
    "\n",
    "The only difference between TRAIN and DEV/TEST set formats is that the final column (labels) will be omitted from the DEV/TEST set files. The first column (unique instance IDs) are also used for the submission output format.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run in terminal:\n",
    "# python baseline.py --train ../data_es_en/es_en.slam.20190204.train --test ../data_es_en/es_en.slam.20190204.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duolingo Code\n",
    "\n",
    "The following classes and functions are from a file called __*baseline.py*__, publicly available on the [website above](#https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/8SWHNO). The code and accompanying datasets were released as part of the [2018 Duolingo Shared Task Challenge on Second Language Acquisition Modeling (SLAM)](#https://sharedtask.duolingo.com/2018.html). \n",
    "\n",
    "- Source: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/8SWHNO \n",
    "- Resource: https://sharedtask.duolingo.com/2018.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Duolingo SLAM Shared Task - Baseline Model\n",
    "\n",
    "This baseline model loads the training and test data that you pass in via --train and --test arguments for a particular\n",
    "track (course), storing the resulting data in InstanceData objects, one for each instance. The code then creates the\n",
    "features we'll use for logistic regression, storing the resulting LogisticRegressionInstance objects, then uses those to\n",
    "train a regularized logistic model with SGD, and then makes predictions for the test set and dumps them to a CSV file\n",
    "specified with the --pred argument, in a format appropriate to be read in and graded by the eval.py script.\n",
    "\n",
    "We elect to use two different classes, InstanceData and LogisticRegressionInstance, to delineate the boundary between\n",
    "the two purposes of this code; the first being to act as a user-friendly interface to the data, and the second being to\n",
    "train and run a baseline model as an example. Competitors may feel free to use InstanceData in their own code, but\n",
    "should consider replacing the LogisticRegressionInstance with a class more appropriate for the model they construct.\n",
    "\n",
    "This code is written to be compatible with both Python 2 or 3, at the expense of dependency on the future library. This\n",
    "code does not depend on any other Python libraries besides future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "from collections import defaultdict, namedtuple\n",
    "from io import open\n",
    "import math\n",
    "import os\n",
    "from random import shuffle, uniform\n",
    "\n",
    "from future.builtins import range\n",
    "from future.utils import iteritems\n",
    "\n",
    "# Sigma is the L2 prior variance, regularizing the baseline model. Smaller sigma means more regularization.\n",
    "_DEFAULT_SIGMA = 20.0\n",
    "\n",
    "# Eta is the learning rate/step size for SGD. Larger means larger step size.\n",
    "_DEFAULT_ETA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Executes the baseline model. This loads the training data, training labels, and dev data, then trains a logistic\n",
    "    regression model, then dumps predictions to the specified file.\n",
    "\n",
    "    Modify the middle of this code, between the two commented blocks, to create your own model.\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Duolingo shared task baseline model')\n",
    "    parser.add_argument('--train', help='Training file name' , required=True)\n",
    "    parser.add_argument('--test', help='Test file name, to make predictions on' , required=True)\n",
    "    parser.add_argument('--pred', help='Output file name for predictions, defaults to test_name.pred')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not args.pred:\n",
    "        args.pred = args.test + '.pred'\n",
    "\n",
    "    assert os.path.isfile(args.train)\n",
    "    assert os.path.isfile(args.test)\n",
    "\n",
    "    # Assert that the train course matches the test course\n",
    "    assert os.path.basename(args.train)[:5] == os.path.basename(args.test)[:5]\n",
    "\n",
    "    training_data, training_labels = load_data(args.train)\n",
    "    test_data = load_data(args.test)\n",
    "\n",
    "    ####################################################################################\n",
    "    # Here is the delineation between loading the data and running the baseline model. #\n",
    "    # Replace the code between this and the next comment block with your own.          #\n",
    "    ####################################################################################\n",
    "\n",
    "    training_instances = [LogisticRegressionInstance(features=instance_data.to_features(),\n",
    "                                                     label=training_labels[instance_data.instance_id],\n",
    "                                                     name=instance_data.instance_id\n",
    "                                                     ) for instance_data in training_data]\n",
    "\n",
    "    test_instances = [LogisticRegressionInstance(features=instance_data.to_features(),\n",
    "                                                 label=None,\n",
    "                                                 name=instance_data.instance_id\n",
    "                                                 ) for instance_data in test_data]\n",
    "\n",
    "    logistic_regression_model = LogisticRegression()\n",
    "    logistic_regression_model.train(training_instances, iterations=10)\n",
    "\n",
    "    predictions = logistic_regression_model.predict_test_set(test_instances)\n",
    "\n",
    "    ####################################################################################\n",
    "    # This ends the baseline model code; now we just write predictions.                #\n",
    "    ####################################################################################\n",
    "\n",
    "    with open(args.pred, 'wt') as f:\n",
    "        for instance_id, prediction in iteritems(predictions):\n",
    "            f.write(instance_id + ' ' + str(prediction) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
    "\n",
    "    Parameters:\n",
    "        filename: the location of the training or test data you want to load.\n",
    "\n",
    "    Returns:\n",
    "        data: a list of InstanceData objects from that data type and track.\n",
    "        labels (optional): if you specified training data, a dict of instance_id:label pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    # 'data' stores a list of 'InstanceData's as values.\n",
    "    data = []\n",
    "\n",
    "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
    "    training = False\n",
    "    if filename.find('train') != -1:\n",
    "        training = True\n",
    "\n",
    "    if training:\n",
    "        labels = dict()\n",
    "\n",
    "    num_exercises = 0\n",
    "    print('Loading instances...')\n",
    "    instance_properties = dict()\n",
    "\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "            if len(line) == 0:\n",
    "                num_exercises += 1\n",
    "                if num_exercises % 100000 == 0:\n",
    "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                instance_properties = dict()\n",
    "\n",
    "            # If the line starts with #, then we're beginning a new exercise\n",
    "            elif line[0] == '#':\n",
    "                if 'prompt' in line:\n",
    "                    instance_properties['prompt'] = line.split(':')[1]\n",
    "                else:\n",
    "                    list_of_exercise_parameters = line[2:].split()\n",
    "                    for exercise_parameter in list_of_exercise_parameters:\n",
    "                        [key, value] = exercise_parameter.split(':')\n",
    "                        if key == 'countries':\n",
    "                            value = value.split('|')\n",
    "                        elif key == 'days':\n",
    "                            value = float(value)\n",
    "                        elif key == 'time':\n",
    "                            if value == 'null':\n",
    "                                value = None\n",
    "                            else:\n",
    "                                assert '.' not in value\n",
    "                                value = int(value)\n",
    "                        instance_properties[key] = value\n",
    "\n",
    "            # Otherwise we're parsing a new Instance for the current exercise\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if training:\n",
    "                    assert len(line) == 7\n",
    "                else:\n",
    "                    assert len(line) == 6\n",
    "                assert len(line[0]) == 12\n",
    "\n",
    "                instance_properties['instance_id'] = line[0]\n",
    "\n",
    "                instance_properties['token'] = line[1]\n",
    "                instance_properties['part_of_speech'] = line[2]\n",
    "\n",
    "                instance_properties['morphological_features'] = dict()\n",
    "                for l in line[3].split('|'):\n",
    "                    [key, value] = l.split('=')\n",
    "                    if key == 'Person':\n",
    "                        value = int(value)\n",
    "                    instance_properties['morphological_features'][key] = value\n",
    "\n",
    "                instance_properties['dependency_label'] = line[4]\n",
    "                instance_properties['dependency_edge_head'] = int(line[5])\n",
    "                if training:\n",
    "                    label = float(line[6])\n",
    "                    labels[instance_properties['instance_id']] = label\n",
    "                data.append(InstanceData(instance_properties=instance_properties))\n",
    "\n",
    "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
    "              ' exercises.\\n')\n",
    "\n",
    "    if training:\n",
    "        return data, labels\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceData(object):\n",
    "    \"\"\"\n",
    "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
    "    data, and provides a launching point for deriving your own features from the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, instance_properties):\n",
    "\n",
    "        # Parameters specific to this instance\n",
    "        self.instance_id = instance_properties['instance_id']\n",
    "        self.token = instance_properties['token']\n",
    "        self.part_of_speech = instance_properties['part_of_speech']\n",
    "        self.morphological_features = instance_properties['morphological_features']\n",
    "        self.dependency_label = instance_properties['dependency_label']\n",
    "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
    "\n",
    "        # Derived parameters specific to this instance\n",
    "        self.exercise_index = int(self.instance_id[8:10])\n",
    "        self.token_index = int(self.instance_id[10:12])\n",
    "\n",
    "        # Derived parameters specific to this exercise\n",
    "        self.exercise_id = self.instance_id[:10]\n",
    "\n",
    "        # Parameters shared across the whole session\n",
    "        self.user = instance_properties['user']\n",
    "        self.countries = instance_properties['countries']\n",
    "        self.days = instance_properties['days']\n",
    "        self.client = instance_properties['client']\n",
    "        self.session = instance_properties['session']\n",
    "        self.format = instance_properties['format']\n",
    "        self.time = instance_properties['time']\n",
    "        self.prompt = instance_properties.get('prompt', None)\n",
    "\n",
    "        # Derived parameters shared across the whole session\n",
    "        self.session_id = self.instance_id[:8]\n",
    "\n",
    "    def to_features(self):\n",
    "        \"\"\"\n",
    "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
    "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
    "        input dictionary, 'instance_properties'.\n",
    "\n",
    "        Returns:\n",
    "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
    "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
    "        \"\"\"\n",
    "        to_return = dict()\n",
    "\n",
    "        to_return['bias'] = 1.0\n",
    "        to_return['user:' + self.user] = 1.0\n",
    "        to_return['format:' + self.format] = 1.0\n",
    "        to_return['token:' + self.token.lower()] = 1.0\n",
    "\n",
    "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
    "        for morphological_feature in self.morphological_features:\n",
    "            to_return['morphological_feature:' + morphological_feature] = 1.0\n",
    "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
    "\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionInstance(namedtuple('Instance', ['features', 'label', 'name'])):\n",
    "    \"\"\"\n",
    "    A named tuple for packaging together the instance features, label, and name.\n",
    "    \"\"\"\n",
    "    def __new__(cls, features, label, name):\n",
    "        if label:\n",
    "            if not isinstance(label, (int, float)):\n",
    "                raise TypeError('LogisticRegressionInstance label must be a number.')\n",
    "            label = float(label)\n",
    "        if not isinstance(features, dict):\n",
    "            raise TypeError('LogisticRegressionInstance features must be a dict.')\n",
    "        return super(LogisticRegressionInstance, cls).__new__(cls, features, label, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    \"\"\"\n",
    "    An L2-regularized logistic regression object trained using stochastic gradient descent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=_DEFAULT_SIGMA, eta=_DEFAULT_ETA):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.sigma = sigma  # L2 prior variance\n",
    "        self.eta = eta  # initial learning rate\n",
    "        self.weights = defaultdict(lambda: uniform(-1.0, 1.0)) # weights initialize to random numbers\n",
    "        self.fcounts = None # this forces smaller steps for things we've seen often before\n",
    "\n",
    "    def predict_instance(self, instance):\n",
    "        \"\"\"\n",
    "        This computes the logistic function of the dot product of the instance features and the weights.\n",
    "        We truncate predictions at ~10^(-7) and ~1 - 10^(-7).\n",
    "        \"\"\"\n",
    "        a = min(17., max(-17., sum([float(self.weights[k]) * instance.features[k] for k in instance.features])))\n",
    "        return 1. / (1. + math.exp(-a))\n",
    "\n",
    "    def error(self, instance):\n",
    "        return instance.label - self.predict_instance(instance)\n",
    "\n",
    "    def reset(self):\n",
    "        self.fcounts = defaultdict(int)\n",
    "\n",
    "    def training_update(self, instance):\n",
    "        if self.fcounts is None:\n",
    "            self.reset()\n",
    "        err = self.error(instance)\n",
    "        for k in instance.features:\n",
    "            rate = self.eta / math.sqrt(1 + self.fcounts[k])\n",
    "            # L2 regularization update\n",
    "            if k != 'bias':\n",
    "                self.weights[k] -= rate * self.weights[k] / self.sigma ** 2\n",
    "            # error update\n",
    "            self.weights[k] += rate * err * instance.features[k]\n",
    "            # increment feature count for learning rate\n",
    "            self.fcounts[k] += 1\n",
    "\n",
    "    def train(self, train_set, iterations=10):\n",
    "        for it in range(iterations):\n",
    "            print('Training iteration ' + str(it+1) + '/' + str(iterations) + '...')\n",
    "            shuffle(train_set)\n",
    "            for instance in train_set:\n",
    "                self.training_update(instance)\n",
    "        print('\\n')\n",
    "\n",
    "    def predict_test_set(self, test_set):\n",
    "        return {instance.name: self.predict_instance(instance) for instance in test_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading instances...\n",
      "Loaded 266882 instances across 100000 exercises...\n",
      "Loaded 537453 instances across 200000 exercises...\n",
      "Loaded 804717 instances across 300000 exercises...\n",
      "Loaded 1075884 instances across 400000 exercises...\n",
      "Loaded 1348070 instances across 500000 exercises...\n",
      "Loaded 1620764 instances across 600000 exercises...\n",
      "Loaded 1887018 instances across 700000 exercises...\n",
      "Done loading 1973556 instances across 731896 exercises.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate function above and call the train dataset to load data & labels\n",
    "data, labels = load_data('../data_es_en/es_en.slam.20190204.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.InstanceData at 0x106ad6650>,\n",
       " <__main__.InstanceData at 0x106add710>,\n",
       " <__main__.InstanceData at 0x106e03f90>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at contents of data\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d44lo//L0101 0.0\n",
      "d44lo//L0102 0.0\n",
      "d44lo//L0201 0.0\n",
      "d44lo//L0202 0.0\n",
      "d44lo//L0301 0.0\n"
     ]
    }
   ],
   "source": [
    "# Look at contents of labels\n",
    "i = 5\n",
    "for key, value in labels.items():\n",
    "    if i > 0:\n",
    "        print(key, value)\n",
    "        i -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we convert the data into a dataframe?\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x106ad6650&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x106add710&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x106e03f90&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x106ab8ad0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x10703ca50&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973551</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x1d94b0d10&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973552</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x1d94b21d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973553</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x1d94b2510&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973554</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x1d94b2950&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973555</th>\n",
       "      <td>&lt;__main__.InstanceData object at 0x1d94b2c90&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1973556 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0        <__main__.InstanceData object at 0x106ad6650>\n",
       "1        <__main__.InstanceData object at 0x106add710>\n",
       "2        <__main__.InstanceData object at 0x106e03f90>\n",
       "3        <__main__.InstanceData object at 0x106ab8ad0>\n",
       "4        <__main__.InstanceData object at 0x10703ca50>\n",
       "...                                                ...\n",
       "1973551  <__main__.InstanceData object at 0x1d94b0d10>\n",
       "1973552  <__main__.InstanceData object at 0x1d94b21d0>\n",
       "1973553  <__main__.InstanceData object at 0x1d94b2510>\n",
       "1973554  <__main__.InstanceData object at 0x1d94b2950>\n",
       "1973555  <__main__.InstanceData object at 0x1d94b2c90>\n",
       "\n",
       "[1973556 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Class Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function here or inside the class to iterate over all class attributes and print\n",
    "# def get_attributes(instance_data):\n",
    "#     self_params = {}\n",
    "#     attrs = [instance_id, token, part_of_speech, morphological_features, dependency_label, dependency_edge_head, \n",
    "#              exercise_index, token_index, exercise_id, user, countries, days, client, session, format, time, prompt]\n",
    "#     for attr in attrs:\n",
    "#         self_params[str(attr)] = instance_data.attr\n",
    "        \n",
    "#     return self_params\n",
    "    \n",
    "#  # Additional function by Kelly Slatery\n",
    "#     def get_attributes(self):\n",
    "#         '''Returns a dictionary of all of its attributes'''\n",
    "#         self_params = {}\n",
    "#         for attr in self.__init__    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'user:+H9QWAV4': 1.0,\n",
       " 'format:listen': 1.0,\n",
       " 'token:el': 1.0,\n",
       " 'part_of_speech:DET': 1.0,\n",
       " 'morphological_feature:Definite': 1.0,\n",
       " 'morphological_feature:Gender': 1.0,\n",
       " 'morphological_feature:Number': 1.0,\n",
       " 'morphological_feature:PronType': 1.0,\n",
       " 'morphological_feature:fPOS': 1.0,\n",
       " 'dependency_label:det': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d44lo//L0101'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].instance_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DET'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Definite': 'Def',\n",
       " 'Gender': 'Masc',\n",
       " 'Number': 'Sing',\n",
       " 'PronType': 'Art',\n",
       " 'fPOS': 'DET++'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].morphological_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].dependency_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].dependency_edge_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].exercise_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d44lo//L01'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].exercise_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+H9QWAV4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ios'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lesson'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'listen'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'user:+H9QWAV4': 1.0,\n",
       " 'format:listen': 1.0,\n",
       " 'token:pan': 1.0,\n",
       " 'part_of_speech:NOUN': 1.0,\n",
       " 'morphological_feature:Gender': 1.0,\n",
       " 'morphological_feature:Number': 1.0,\n",
       " 'morphological_feature:fPOS': 1.0,\n",
       " 'dependency_label:ROOT': 1.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': 'Masc', 'Number': 'Sing', 'fPOS': 'NOUN++'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].morphological_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
